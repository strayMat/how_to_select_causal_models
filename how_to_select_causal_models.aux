\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@refcontext{nyt/global//global/global}
\abx@aux@cite{0}{mooney2018bigdata}
\abx@aux@segm{0}{0}{mooney2018bigdata}
\abx@aux@cite{0}{yurkovich2015systematic}
\abx@aux@segm{0}{0}{yurkovich2015systematic}
\abx@aux@cite{0}{desai2020comparison}
\abx@aux@segm{0}{0}{desai2020comparison}
\abx@aux@cite{0}{horng2017creating}
\abx@aux@segm{0}{0}{horng2017creating}
\abx@aux@cite{0}{simon2018predicting}
\abx@aux@segm{0}{0}{simon2018predicting}
\abx@aux@cite{0}{altman2009prognosis}
\abx@aux@segm{0}{0}{altman2009prognosis}
\abx@aux@cite{0}{poldrack2020establishment}
\abx@aux@segm{0}{0}{poldrack2020establishment}
\abx@aux@cite{0}{varoquaux2022evaluating}
\abx@aux@segm{0}{0}{varoquaux2022evaluating}
\abx@aux@cite{0}{fontana2019can}
\abx@aux@segm{0}{0}{fontana2019can}
\abx@aux@cite{0}{snowden_implementation_2011}
\abx@aux@segm{0}{0}{snowden_implementation_2011}
\abx@aux@cite{0}{blakely2020reflection}
\abx@aux@segm{0}{0}{blakely2020reflection}
\abx@aux@cite{0}{robins_role_1986}
\abx@aux@segm{0}{0}{robins_role_1986}
\abx@aux@cite{0}{snowden_implementation_2011}
\abx@aux@segm{0}{0}{snowden_implementation_2011}
\abx@aux@cite{0}{wendling_comparing_2018}
\abx@aux@segm{0}{0}{wendling_comparing_2018}
\abx@aux@cite{0}{black1996we}
\abx@aux@segm{0}{0}{black1996we}
\abx@aux@cite{0}{hernan_methods_2021}
\abx@aux@segm{0}{0}{hernan_methods_2021}
\abx@aux@cite{0}{radley2006off}
\abx@aux@segm{0}{0}{radley2006off}
\abx@aux@cite{0}{hurle2013computational}
\abx@aux@segm{0}{0}{hurle2013computational}
\abx@aux@cite{0}{dudley2011exploiting}
\abx@aux@segm{0}{0}{dudley2011exploiting}
\abx@aux@cite{0}{austin_moving_2015}
\abx@aux@segm{0}{0}{austin_moving_2015}
\abx@aux@cite{0}{grose_use_2020}
\abx@aux@segm{0}{0}{grose_use_2020}
\abx@aux@cite{0}{rosenbaum_central_1983}
\abx@aux@segm{0}{0}{rosenbaum_central_1983}
\abx@aux@cite{0}{wendling_comparing_2018}
\abx@aux@segm{0}{0}{wendling_comparing_2018}
\abx@aux@cite{0}{dorie_automated_2019}
\abx@aux@segm{0}{0}{dorie_automated_2019}
\abx@aux@cite{0}{su2018random}
\abx@aux@segm{0}{0}{su2018random}
\abx@aux@cite{0}{lamont2018identification}
\abx@aux@segm{0}{0}{lamont2018identification}
\abx@aux@cite{0}{hoogland2021tutorial}
\abx@aux@segm{0}{0}{hoogland2021tutorial}
\abx@aux@cite{0}{hill_bayesian_2011}
\abx@aux@segm{0}{0}{hill_bayesian_2011}
\abx@aux@cite{0}{laan_targeted_2011}
\abx@aux@segm{0}{0}{laan_targeted_2011}
\abx@aux@cite{0}{schuler_targeted_2017}
\abx@aux@segm{0}{0}{schuler_targeted_2017}
\abx@aux@cite{0}{powers_methods_2018}
\abx@aux@segm{0}{0}{powers_methods_2018}
\abx@aux@cite{0}{powers_methods_2018}
\abx@aux@segm{0}{0}{powers_methods_2018}
\abx@aux@cite{0}{wager_estimation_2018}
\abx@aux@segm{0}{0}{wager_estimation_2018}
\abx@aux@cite{0}{athey_generalized_2019}
\abx@aux@segm{0}{0}{athey_generalized_2019}
\abx@aux@cite{0}{kunzel_metalearners_2019}
\abx@aux@segm{0}{0}{kunzel_metalearners_2019}
\abx@aux@cite{0}{nie_quasioracle_2017}
\abx@aux@segm{0}{0}{nie_quasioracle_2017}
\abx@aux@cite{0}{chernozhukov_double_2018}
\abx@aux@segm{0}{0}{chernozhukov_double_2018}
\abx@aux@cite{0}{dorie_automated_2019}
\abx@aux@segm{0}{0}{dorie_automated_2019}
\abx@aux@cite{0}{dorie_automated_2019}
\abx@aux@segm{0}{0}{dorie_automated_2019}
\abx@aux@cite{0}{dorie_automated_2019}
\abx@aux@segm{0}{0}{dorie_automated_2019}
\abx@aux@cite{0}{poldrack2020establishment}
\abx@aux@segm{0}{0}{poldrack2020establishment}
\abx@aux@cite{0}{varoquaux2022evaluating}
\abx@aux@segm{0}{0}{varoquaux2022evaluating}
\abx@aux@cite{0}{charlson_new_1987}
\abx@aux@segm{0}{0}{charlson_new_1987}
\@writefile{toc}{\contentsline {section}{\numberline {1}Background}{2}{section.1}\protected@file@percent }
\newlabel{sec:intro}{{1}{2}{Background}{section.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Extending prediction to prescription requires causal model selection}{2}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Objectives and structure of the paper}{2}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Illustration: the best predictor may not estimate best causal effects}{2}{subsection.1.2}\protected@file@percent }
\abx@aux@cite{0}{powers_methods_2018}
\abx@aux@segm{0}{0}{powers_methods_2018}
\abx@aux@cite{0}{schuler_comparison_2018}
\abx@aux@segm{0}{0}{schuler_comparison_2018}
\abx@aux@cite{0}{schuler_comparison_2018}
\abx@aux@segm{0}{0}{schuler_comparison_2018}
\abx@aux@cite{0}{nie_quasioracle_2017}
\abx@aux@segm{0}{0}{nie_quasioracle_2017}
\abx@aux@cite{0}{alaa_validating_2019}
\abx@aux@segm{0}{0}{alaa_validating_2019}
\abx@aux@cite{0}{dorie_automated_2019}
\abx@aux@segm{0}{0}{dorie_automated_2019}
\abx@aux@cite{0}{damour_overlap_2020}
\abx@aux@segm{0}{0}{damour_overlap_2020}
\abx@aux@cite{0}{rolling_model_2014}
\abx@aux@segm{0}{0}{rolling_model_2014}
\abx@aux@cite{0}{gutierrez_causal_2016}
\abx@aux@segm{0}{0}{gutierrez_causal_2016}
\abx@aux@cite{0}{saito_counterfactual_2020}
\abx@aux@segm{0}{0}{saito_counterfactual_2020}
\abx@aux@cite{0}{alaa_validating_2019}
\abx@aux@segm{0}{0}{alaa_validating_2019}
\abx@aux@cite{0}{laan_targeted_2011}
\abx@aux@segm{0}{0}{laan_targeted_2011}
\abx@aux@cite{0}{schuler_targeted_2017}
\abx@aux@segm{0}{0}{schuler_targeted_2017}
\abx@aux@cite{0}{chernozhukov_double_2018}
\abx@aux@segm{0}{0}{chernozhukov_double_2018}
\abx@aux@cite{0}{johansson_generalization_2021}
\abx@aux@segm{0}{0}{johansson_generalization_2021}
\abx@aux@cite{0}{johansson_generalization_2021}
\abx@aux@segm{0}{0}{johansson_generalization_2021}
\abx@aux@cite{0}{schuler_comparison_2018}
\abx@aux@segm{0}{0}{schuler_comparison_2018}
\abx@aux@cite{0}{naimi2023defining}
\abx@aux@segm{0}{0}{naimi2023defining}
\abx@aux@cite{0}{imbens_causal_2015}
\abx@aux@segm{0}{0}{imbens_causal_2015}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Prior work: model selection for outcome modeling (g-computation)}{3}{subsection.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Simulation studies of causal model selection}{3}{section*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Theoretical studies of causal model selection}{3}{section*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Statistical guarantees on causal estimation procedures}{3}{section*.6}\protected@file@percent }
\abx@aux@cite{0}{rubin_causal_2005}
\abx@aux@segm{0}{0}{rubin_causal_2005}
\abx@aux@cite{0}{damour_overlap_2020}
\abx@aux@segm{0}{0}{damour_overlap_2020}
\abx@aux@cite{0}{robins_new_1986}
\abx@aux@segm{0}{0}{robins_new_1986}
\abx@aux@cite{0}{snowden_implementation_2011}
\abx@aux@segm{0}{0}{snowden_implementation_2011}
\abx@aux@cite{0}{robinson_rootnconsistent_1988}
\abx@aux@segm{0}{0}{robinson_rootnconsistent_1988}
\abx@aux@cite{0}{rosenbaum_central_1983}
\abx@aux@segm{0}{0}{rosenbaum_central_1983}
\abx@aux@cite{0}{chernozhukov_double_2018}
\abx@aux@segm{0}{0}{chernozhukov_double_2018}
\abx@aux@cite{0}{schulam_reliable_2017}
\abx@aux@segm{0}{0}{schulam_reliable_2017}
\abx@aux@cite{0}{hill_bayesian_2011}
\abx@aux@segm{0}{0}{hill_bayesian_2011}
\@writefile{toc}{\contentsline {section}{\numberline {2}Formal setting of causal inference and model selection}{4}{section.2}\protected@file@percent }
\newlabel{sec:framework}{{2}{4}{Formal setting of causal inference and model selection}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}The Neyman-Rubin Potential Outcomes framework}{4}{subsection.2.1}\protected@file@percent }
\newlabel{sec:neyman_rubin}{{2.1}{4}{The Neyman-Rubin Potential Outcomes framework}{subsection.2.1}{}}
\@writefile{toc}{\contentsline {paragraph}{Settings}{4}{section*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Causal assumptions}{4}{section*.8}\protected@file@percent }
\newlabel{subsec:estimators}{{2.1}{4}{Estimating treatment effects with outcome models}{section*.9}{}}
\@writefile{toc}{\contentsline {paragraph}{Estimating treatment effects with outcome models}{4}{section*.9}\protected@file@percent }
\newlabel{eq:mu_identification}{{1}{4}{Estimating treatment effects with outcome models}{equation.2.1}{}}
\newlabel{eq:tau_population}{{2}{4}{Estimating treatment effects with outcome models}{equation.2.2}{}}
\newlabel{def:mu_a}{{3}{4}{Estimating treatment effects with outcome models}{equation.2.3}{}}
\newlabel{eq:ate_estimate}{{4}{4}{Estimating treatment effects with outcome models}{equation.2.4}{}}
\newlabel{eq:cate_estimate}{{5}{4}{Estimating treatment effects with outcome models}{equation.2.5}{}}
\@writefile{toc}{\contentsline {paragraph}{Robinson decomposition}{4}{section*.10}\protected@file@percent }
\newlabel{def:m}{{6}{4}{Robinson decomposition}{equation.2.6}{}}
\newlabel{def:propensity_score}{{7}{4}{Robinson decomposition}{equation.2.7}{}}
\newlabel{eq:r_decomposition}{{8}{4}{Robinson decomposition}{equation.2.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Model-selection risks, oracle and feasible}{4}{subsection.2.2}\protected@file@percent }
\newlabel{sec:problem:model_selection}{{2.2}{4}{Model-selection risks, oracle and feasible}{subsection.2.2}{}}
\newlabel{sec:problem:causal_selection}{{2.2}{4}{Causal model selection}{section*.11}{}}
\@writefile{toc}{\contentsline {paragraph}{Causal model selection}{4}{section*.11}\protected@file@percent }
\newlabel{eq:causal_model_selection}{{9}{4}{Causal model selection}{equation.2.9}{}}
\abx@aux@cite{0}{shalit_estimating_2017}
\abx@aux@segm{0}{0}{shalit_estimating_2017}
\abx@aux@cite{0}{vanderlaan_unified_2003}
\abx@aux@segm{0}{0}{vanderlaan_unified_2003}
\abx@aux@cite{0}{wager_estimation_2018}
\abx@aux@segm{0}{0}{wager_estimation_2018}
\abx@aux@cite{0}{athey2016recursive}
\abx@aux@segm{0}{0}{athey2016recursive}
\abx@aux@cite{0}{gutierrez_causal_2016}
\abx@aux@segm{0}{0}{gutierrez_causal_2016}
\abx@aux@cite{0}{wager_estimation_2018}
\abx@aux@segm{0}{0}{wager_estimation_2018}
\abx@aux@cite{0}{kunzel_metalearners_2019}
\abx@aux@segm{0}{0}{kunzel_metalearners_2019}
\abx@aux@cite{0}{nie_quasioracle_2017}
\abx@aux@segm{0}{0}{nie_quasioracle_2017}
\abx@aux@cite{0}{robinson_rootnconsistent_1988}
\abx@aux@segm{0}{0}{robinson_rootnconsistent_1988}
\abx@aux@cite{0}{nie_quasioracle_2017}
\abx@aux@segm{0}{0}{nie_quasioracle_2017}
\abx@aux@cite{0}{schuler_comparison_2018}
\abx@aux@segm{0}{0}{schuler_comparison_2018}
\abx@aux@cite{0}{robinson_rootnconsistent_1988}
\abx@aux@segm{0}{0}{robinson_rootnconsistent_1988}
\abx@aux@cite{0}{nie_quasioracle_2017}
\abx@aux@segm{0}{0}{nie_quasioracle_2017}
\abx@aux@cite{0}{hill_bayesian_2011}
\abx@aux@segm{0}{0}{hill_bayesian_2011}
\abx@aux@cite{0}{schuler_comparison_2018}
\abx@aux@segm{0}{0}{schuler_comparison_2018}
\abx@aux@cite{0}{vanderlaan_unified_2003}
\abx@aux@segm{0}{0}{vanderlaan_unified_2003}
\abx@aux@cite{0}{wager_estimation_2018}
\abx@aux@segm{0}{0}{wager_estimation_2018}
\abx@aux@cite{0}{nie_quasioracle_2017}
\abx@aux@segm{0}{0}{nie_quasioracle_2017}
\abx@aux@cite{0}{nie_quasioracle_2017}
\abx@aux@segm{0}{0}{nie_quasioracle_2017}
\abx@aux@cite{0}{schuler_comparison_2018}
\abx@aux@segm{0}{0}{schuler_comparison_2018}
\abx@aux@cite{0}{schuler_comparison_2018}
\abx@aux@segm{0}{0}{schuler_comparison_2018}
\abx@aux@cite{0}{swaminathan_counterfactual_2015}
\abx@aux@segm{0}{0}{swaminathan_counterfactual_2015}
\abx@aux@cite{0}{ionides_truncated_2008}
\abx@aux@segm{0}{0}{ionides_truncated_2008}
\abx@aux@cite{0}{shalit_estimating_2017}
\abx@aux@segm{0}{0}{shalit_estimating_2017}
\abx@aux@cite{0}{johansson_generalization_2021}
\abx@aux@segm{0}{0}{johansson_generalization_2021}
\abx@aux@cite{0}{johansson_generalization_2021}
\abx@aux@segm{0}{0}{johansson_generalization_2021}
\newlabel{paragraph:oracle_metrics}{{2.2}{5}{The $\tau \text {-risk}$: an oracle error risk}{section*.12}{}}
\@writefile{toc}{\contentsline {paragraph}{The $\tau \text  {-risk}$: an oracle error risk}{5}{section*.12}\protected@file@percent }
\newlabel{def:tau_risk}{{1}{5}{$\tau \text {-risk}(f)$}{definition.1}{}}
\newlabel{eq:tau_risk}{{1}{5}{$\tau \text {-risk}(f)$}{definition.1}{}}
\newlabel{paragraph:feasible_metrics}{{2.2}{5}{Feasible error risks}{section*.13}{}}
\@writefile{toc}{\contentsline {paragraph}{Feasible error risks}{5}{section*.13}\protected@file@percent }
\newlabel{def:mu_risk}{{2}{5}{Factual $\mu \text {-risk}$}{definition.2}{}}
\newlabel{eq:mu_risk}{{2}{5}{Factual $\mu \text {-risk}$}{definition.2}{}}
\newlabel{def:mu_ipw_risk}{{3}{5}{$\mu \text {-risk}_{IPW}^{\star }$}{definition.3}{}}
\newlabel{eq:mu_ipw_risk}{{3}{5}{$\mu \text {-risk}_{IPW}^{\star }$}{definition.3}{}}
\newlabel{def:tau_ipw_risk}{{4}{5}{$\tau \text {-risk}^{\star }_{IPW}$}{definition.4}{}}
\newlabel{def:u_risk}{{5}{5}{$U\text {-risk}^{\star }$}{definition.5}{}}
\newlabel{def:r_risk}{{6}{5}{$R\text {-risk}^{\star }$}{definition.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Estimation and model selection procedure}{5}{subsection.2.3}\protected@file@percent }
\newlabel{problem:estimation_procedure}{{2.3}{5}{Estimation and model selection procedure}{subsection.2.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Theory: Links between feasible and oracle risks}{5}{section.3}\protected@file@percent }
\newlabel{sec:theory}{{3}{5}{Theory: Links between feasible and oracle risks}{section.3}{}}
\newlabel{eq:residuals}{{3}{5}{Theory: Links between feasible and oracle risks}{section.3}{}}
\abx@aux@cite{0}{johansson_generalization_2021}
\abx@aux@segm{0}{0}{johansson_generalization_2021}
\abx@aux@cite{0}{schuler_comparison_2018}
\abx@aux@segm{0}{0}{schuler_comparison_2018}
\abx@aux@cite{0}{schuler_comparison_2018}
\abx@aux@segm{0}{0}{schuler_comparison_2018}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Upper bound of $\tau \text  {-risk}$ with $\mu \text  {-risk}_{IPW}$}{6}{subsection.3.1}\protected@file@percent }
\newlabel{theory:mu_risk_ipw_bound}{{3.1}{6}{Upper bound of $\tau \text {-risk}$ with $\mu \text {-risk}_{IPW}$}{subsection.3.1}{}}
\newlabel{theory:prop:mu_risk_ipw_bound}{{1}{6}{Upper bound with $\mu \text {-risk}_{IPW}$}{proposition.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Reformulation of the $R\text  {-risk}$ as reweighted $\tau \text  {-risk}$}{6}{subsection.3.2}\protected@file@percent }
\newlabel{theory:r_risk_rewrite}{{3.2}{6}{Reformulation of the $R\text {-risk}$ as reweighted $\tau \text {-risk}$}{subsection.3.2}{}}
\newlabel{theory:prop:r_risk_rewrite}{{2}{6}{$R \text {-risk}$ as reweighted $\tau \text {-risk}$}{proposition.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Interesting special cases}{6}{subsection.3.3}\protected@file@percent }
\newlabel{remark:rct}{{3.3}{6}{Randomization special case}{section*.17}{}}
\@writefile{toc}{\contentsline {paragraph}{Randomization special case}{6}{section*.17}\protected@file@percent }
\newlabel{remark:bayes_oracle}{{3.3}{6}{Oracle Bayes predictor}{section*.18}{}}
\@writefile{toc}{\contentsline {paragraph}{Oracle Bayes predictor}{6}{section*.18}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Empirical Study}{6}{section.4}\protected@file@percent }
\newlabel{sec:empirical_study}{{4}{6}{Empirical Study}{section.4}{}}
\abx@aux@cite{0}{schuler_comparison_2018}
\abx@aux@segm{0}{0}{schuler_comparison_2018}
\abx@aux@cite{0}{alaa_validating_2019}
\abx@aux@segm{0}{0}{alaa_validating_2019}
\abx@aux@cite{0}{howe_splines_2011}
\abx@aux@segm{0}{0}{howe_splines_2011}
\abx@aux@cite{0}{perperoglou_review_2019}
\abx@aux@segm{0}{0}{perperoglou_review_2019}
\abx@aux@cite{0}{rahimi_random_2008}
\abx@aux@segm{0}{0}{rahimi_random_2008}
\abx@aux@cite{0}{kunzel_metalearners_2019}
\abx@aux@segm{0}{0}{kunzel_metalearners_2019}
\abx@aux@cite{0}{nie_quasioracle_2017}
\abx@aux@segm{0}{0}{nie_quasioracle_2017}
\abx@aux@cite{0}{kunzel_metalearners_2019}
\abx@aux@segm{0}{0}{kunzel_metalearners_2019}
\abx@aux@cite{0}{dorie_automated_2019}
\abx@aux@segm{0}{0}{dorie_automated_2019}
\abx@aux@cite{0}{niswander_women_1972}
\abx@aux@segm{0}{0}{niswander_women_1972}
\abx@aux@cite{0}{shimoni_benchmarking_2018}
\abx@aux@segm{0}{0}{shimoni_benchmarking_2018}
\abx@aux@cite{0}{macdorman_infant_1998}
\abx@aux@segm{0}{0}{macdorman_infant_1998}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Caussim: Extensive simulation settings}{7}{subsection.4.1}\protected@file@percent }
\newlabel{subsec:simulations}{{4.1}{7}{Caussim: Extensive simulation settings}{subsection.4.1}{}}
\@writefile{toc}{\contentsline {paragraph}{Data Generation Process}{7}{section*.19}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Family of candidate estimators}{7}{section*.21}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Semi-simulated datasets}{7}{subsection.4.2}\protected@file@percent }
\newlabel{semi_simulated:datasets}{{4.2}{7}{Datasets}{section*.22}{}}
\@writefile{toc}{\contentsline {paragraph}{Datasets}{7}{section*.22}\protected@file@percent }
\abx@aux@cite{0}{louizos_causal_2017}
\abx@aux@segm{0}{0}{louizos_causal_2017}
\abx@aux@cite{0}{almond_costs_2005}
\abx@aux@segm{0}{0}{almond_costs_2005}
\abx@aux@cite{0}{curth_really_2021}
\abx@aux@segm{0}{0}{curth_really_2021}
\abx@aux@cite{0}{schuler_targeted_2017}
\abx@aux@segm{0}{0}{schuler_targeted_2017}
\abx@aux@cite{0}{swaminathan_counterfactual_2015}
\abx@aux@segm{0}{0}{swaminathan_counterfactual_2015}
\abx@aux@cite{0}{ionides_truncated_2008}
\abx@aux@segm{0}{0}{ionides_truncated_2008}
\abx@aux@cite{0}{austin_introduction_2011}
\abx@aux@segm{0}{0}{austin_introduction_2011}
\abx@aux@cite{0}{austin_moving_2015}
\abx@aux@segm{0}{0}{austin_moving_2015}
\abx@aux@cite{0}{damour_overlap_2020}
\abx@aux@segm{0}{0}{damour_overlap_2020}
\abx@aux@cite{0}{johansson_generalization_2021}
\abx@aux@segm{0}{0}{johansson_generalization_2021}
\abx@aux@cite{0}{kendall_new_1938}
\abx@aux@segm{0}{0}{kendall_new_1938}
\abx@aux@cite{0}{athey2016recursive}
\abx@aux@segm{0}{0}{athey2016recursive}
\abx@aux@cite{0}{gutierrez_causal_2016}
\abx@aux@segm{0}{0}{gutierrez_causal_2016}
\newlabel{semi_simulated:candidate_estimators}{{4.2}{8}{Family of candidate estimators}{section*.23}{}}
\@writefile{toc}{\contentsline {paragraph}{Family of candidate estimators}{8}{section*.23}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Nuisance estimators}{8}{section*.24}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Measuring overlap between treated and non treated}{8}{subsection.4.3}\protected@file@percent }
\newlabel{subsec:measuring_overlap}{{4.3}{8}{Measuring overlap between treated and non treated}{subsection.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Empirical results: factors driving good model selection across datasets}{8}{subsection.4.4}\protected@file@percent }
\newlabel{empirical_study:results}{{4.4}{8}{Empirical results: factors driving good model selection across datasets}{subsection.4.4}{}}
\@writefile{toc}{\contentsline {paragraph}{The $R\text  {-risk}$ is the best metric}{8}{section*.26}\protected@file@percent }
\abx@aux@cite{0}{nie_quasioracle_2017}
\abx@aux@segm{0}{0}{nie_quasioracle_2017}
\abx@aux@cite{0}{daniel2018double}
\abx@aux@segm{0}{0}{daniel2018double}
\abx@aux@cite{0}{naimi2021challenges}
\abx@aux@segm{0}{0}{naimi2021challenges}
\abx@aux@cite{0}{kennedy2020optimal}
\abx@aux@segm{0}{0}{kennedy2020optimal}
\abx@aux@cite{0}{nie_quasioracle_2017}
\abx@aux@segm{0}{0}{nie_quasioracle_2017}
\abx@aux@cite{0}{chernozhukov_double_2018}
\abx@aux@segm{0}{0}{chernozhukov_double_2018}
\@writefile{toc}{\contentsline {paragraph}{Model selection is harder in settings of low population overlap}{9}{section*.27}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Nuisances can be estimated on the same data as outcome models}{9}{section*.29}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Stacked models are good overall estimators of nuisances}{9}{section*.31}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Use 90\% of the data to estimate outcome models, 10\% to select them}{9}{section*.33}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion and conclusion}{9}{section.5}\protected@file@percent }
\newlabel{sec:discussion}{{5}{9}{Discussion and conclusion}{section.5}{}}
\abx@aux@cite{0}{schuler_comparison_2018}
\abx@aux@segm{0}{0}{schuler_comparison_2018}
\abx@aux@cite{0}{schuler_comparison_2018}
\abx@aux@segm{0}{0}{schuler_comparison_2018}
\abx@aux@cite{0}{chernozhukov_double_2018}
\abx@aux@segm{0}{0}{chernozhukov_double_2018}
\abx@aux@cite{0}{austin2017estimating}
\abx@aux@segm{0}{0}{austin2017estimating}
\abx@aux@cite{0}{rothman2008case}
\abx@aux@segm{0}{0}{rothman2008case}
\abx@aux@cite{0}{colnet2023risk}
\abx@aux@segm{0}{0}{colnet2023risk}
\abx@aux@cite{0}{platt_probabilistic_1999}
\abx@aux@segm{0}{0}{platt_probabilistic_1999}
\abx@aux@cite{0}{zadrozny_obtaining_2001}
\abx@aux@segm{0}{0}{zadrozny_obtaining_2001}
\abx@aux@cite{0}{niculescu-mizil_predicting_2005}
\abx@aux@segm{0}{0}{niculescu-mizil_predicting_2005}
\abx@aux@cite{0}{minderer_revisiting_2021}
\abx@aux@segm{0}{0}{minderer_revisiting_2021}
\abx@aux@cite{0}{perez2022beyond}
\abx@aux@segm{0}{0}{perez2022beyond}
\@writefile{toc}{\contentsline {paragraph}{Extension to binary outcome}{10}{section*.35}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Going further}{10}{section*.36}\protected@file@percent }
\abx@aux@cite{0}{bouthillier_accounting_2021}
\abx@aux@segm{0}{0}{bouthillier_accounting_2021}
\abx@aux@cite{0}{pedregosa_scikitlearn_2011}
\abx@aux@segm{0}{0}{pedregosa_scikitlearn_2011}
\abx@aux@cite{0}{rubin_causal_2005}
\abx@aux@segm{0}{0}{rubin_causal_2005}
\abx@aux@cite{0}{rosenbaum_central_1983}
\abx@aux@segm{0}{0}{rosenbaum_central_1983}
\abx@aux@cite{0}{damour_overlap_2020}
\abx@aux@segm{0}{0}{damour_overlap_2020}
\abx@aux@cite{0}{hernan_causal_2020}
\abx@aux@segm{0}{0}{hernan_causal_2020}
\abx@aux@cite{0}{jesson_identifying_2020}
\abx@aux@segm{0}{0}{jesson_identifying_2020}
\abx@aux@cite{0}{shalit_estimating_2017}
\abx@aux@segm{0}{0}{shalit_estimating_2017}
\@writefile{toc}{\contentsline {section}{\numberline {A}Variability of ATE estimation on ACIC 2016}{15}{appendix.A}\protected@file@percent }
\newlabel{apd:toy_example:acic_2016_ate_variability}{{A}{15}{Variability of ATE estimation on ACIC 2016}{appendix.A}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Hyper-parameters grid used for ACIC 2016 ATE variability\relax }}{15}{table.caption.41}\protected@file@percent }
\newlabel{apd:toy_example:acic_2016_ate_variability:table}{{2}{15}{Hyper-parameters grid used for ACIC 2016 ATE variability\relax }{table.caption.41}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Causal assumptions}{15}{appendix.B}\protected@file@percent }
\newlabel{apd:causal_assumptions}{{B}{15}{Causal assumptions}{appendix.B}{}}
\newlabel{assumption:ignorability}{{1}{15}{Unconfoundedness}{assumption.1}{}}
\newlabel{eq:ignorability}{{1}{15}{Unconfoundedness}{assumption.1}{}}
\newlabel{assumption:overlap}{{2}{15}{Overlap, also known as Positivity)}{assumption.2}{}}
\newlabel{eq:overlap}{{2}{15}{Overlap, also known as Positivity)}{assumption.2}{}}
\newlabel{assumption:consistency}{{3}{15}{Consistency}{assumption.3}{}}
\newlabel{eq:consistancy}{{3}{15}{Consistency}{assumption.3}{}}
\newlabel{assumption:generalization}{{4}{15}{Generalization}{assumption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C}Proofs: Links between feasible and oracle risks}{15}{appendix.C}\protected@file@percent }
\newlabel{apd:proofs}{{C}{15}{Proofs: Links between feasible and oracle risks}{appendix.C}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.1}Upper bound of $\tau \text  {-risk}$ with $\mu \text  {-risk}_{IPW}$}{15}{subsection.C.1}\protected@file@percent }
\newlabel{apd:proofs:mu_risk_ipw_bound}{{C.1}{15}{Upper bound of $\tau \text {-risk}$ with $\mu \text {-risk}_{IPW}$}{subsection.C.1}{}}
\newlabel{mu_risk_a}{{7}{15}{Population Factual $\mu \text {-risk}$}{definition.7}{}}
\abx@aux@cite{0}{robinson_rootnconsistent_1988}
\abx@aux@segm{0}{0}{robinson_rootnconsistent_1988}
\newlabel{apd:proofs:mu_risk_ipw_link_mu}{{1}{16}{Mean-variance decomposition}{lemma.1}{}}
\newlabel{apd:proofs:prop:upper_bound}{{1}{16}{Upper bound with mu-IPW}{proposition*.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.2}Reformulation of the $R\text  {-risk}$ as reweighted $\tau \text  {-risk}$}{16}{subsection.C.2}\protected@file@percent }
\newlabel{apd:proofs:r_risk_rewrite}{{C.2}{16}{Reformulation of the $R\text {-risk}$ as reweighted $\tau \text {-risk}$}{subsection.C.2}{}}
\newlabel{apd:proofs:prop:r_risk_rewrite}{{2}{16}{$R\text {-risk}$ as reweighted $\tau \text {-risk}$}{proposition*.2}{}}
\newlabel{apd:eq:r_decomposition}{{17}{16}{$R\text {-risk}$ as reweighted $\tau \text {-risk}$}{equation.C.17}{}}
\abx@aux@cite{0}{gretton2012kernel}
\abx@aux@segm{0}{0}{gretton2012kernel}
\abx@aux@cite{0}{shalit_estimating_2017}
\abx@aux@segm{0}{0}{shalit_estimating_2017}
\abx@aux@cite{0}{johansson_generalization_2021}
\abx@aux@segm{0}{0}{johansson_generalization_2021}
\abx@aux@cite{0}{sriperumbudur_integral_2009}
\abx@aux@segm{0}{0}{sriperumbudur_integral_2009}
\@writefile{toc}{\contentsline {section}{\numberline {D}Measuring overlap}{17}{appendix.D}\protected@file@percent }
\newlabel{apd:motivation_ntv}{{D}{17}{Measuring overlap}{appendix.D}{}}
\@writefile{toc}{\contentsline {paragraph}{Motivation of the Normalized Total Variation}{17}{section*.42}\protected@file@percent }
\newlabel{eq:ntv}{{18}{17}{Motivation of the Normalized Total Variation}{equation.D.18}{}}
\abx@aux@cite{0}{dorie_automated_2019}
\abx@aux@segm{0}{0}{dorie_automated_2019}
\abx@aux@cite{0}{dorie_automated_2019}
\abx@aux@segm{0}{0}{dorie_automated_2019}
\abx@aux@cite{0}{rahimi_random_2008}
\abx@aux@segm{0}{0}{rahimi_random_2008}
\@writefile{toc}{\contentsline {paragraph}{Measuring overlap without the oracle propensity scores:}{18}{section*.43}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Empirical arguments}{18}{section*.44}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Estimating NTV in practice}{18}{section*.45}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {E}Experiments}{18}{appendix.E}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {E.1}Details on the data generation process}{18}{subsection.E.1}\protected@file@percent }
\newlabel{apd:experiments:generation}{{E.1}{18}{Details on the data generation process}{subsection.E.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces a) Without calibration, estimation of NTV is not trivial even for boosting models. b) Calibrated classifiers are able to recover the true Normalized Total Variation for all datasets where it is available.\relax }}{19}{figure.caption.46}\protected@file@percent }
\newlabel{apd:overlap:ntv_approximation}{{10}{19}{a) Without calibration, estimation of NTV is not trivial even for boosting models. b) Calibrated classifiers are able to recover the true Normalized Total Variation for all datasets where it is available.\relax }{figure.caption.46}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces NTV recovers well the overlap settings described in the ACIC paper \blx@tocontentsinit {0}\cite {dorie_automated_2019}\relax }}{20}{figure.caption.47}\protected@file@percent }
\newlabel{apd:overlap:penalized_overlap}{{11}{20}{NTV recovers well the overlap settings described in the ACIC paper \cite {dorie_automated_2019}\relax }{figure.caption.47}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Good correlation between overlap measured as normalized Total Variation and Maximum Mean Discrepancy (200 sampled Caussim datasets)\relax }}{20}{figure.caption.48}\protected@file@percent }
\newlabel{apd:overlap:caussim:mmd_vs_ntv}{{12}{20}{Good correlation between overlap measured as normalized Total Variation and Maximum Mean Discrepancy (200 sampled Caussim datasets)\relax }{figure.caption.48}{}}
\abx@aux@cite{0}{pedregosa_scikitlearn_2011}
\abx@aux@segm{0}{0}{pedregosa_scikitlearn_2011}
\newlabel{apd:caussim:max_ipw_vs_ntv}{{13a}{21}{\textbf {Caussim}\relax }{figure.caption.49}{}}
\newlabel{sub@apd:caussim:max_ipw_vs_ntv}{{a}{21}{\textbf {Caussim}\relax }{figure.caption.49}{}}
\newlabel{apd:acic_2016:ntv_vs_max_ipw}{{13b}{21}{\textbf {ACIC 2016}\relax }{figure.caption.49}{}}
\newlabel{sub@apd:acic_2016:ntv_vs_max_ipw}{{b}{21}{\textbf {ACIC 2016}\relax }{figure.caption.49}{}}
\newlabel{apd:acic_2018:ntv_vs_max_ipw}{{13c}{21}{\textbf {ACIC 2018}\relax }{figure.caption.49}{}}
\newlabel{sub@apd:acic_2018:ntv_vs_max_ipw}{{c}{21}{\textbf {ACIC 2018}\relax }{figure.caption.49}{}}
\newlabel{apd:twins:ntv_vs_max_ipw}{{13d}{21}{\textbf {TWINS}\relax }{figure.caption.49}{}}
\newlabel{sub@apd:twins:ntv_vs_max_ipw}{{d}{21}{\textbf {TWINS}\relax }{figure.caption.49}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Maximal value of Inverse Propensity Weights increases exponentially with the overlap as measure by Normalized Total Variation.\relax }}{21}{figure.caption.49}\protected@file@percent }
\newlabel{apd:ntv_vs_max_ipw}{{13}{21}{Maximal value of Inverse Propensity Weights increases exponentially with the overlap as measure by Normalized Total Variation.\relax }{figure.caption.49}{}}
\abx@aux@cite{0}{laan_super_2007}
\abx@aux@segm{0}{0}{laan_super_2007}
\abx@aux@cite{0}{pedregosa_scikitlearn_2011}
\abx@aux@segm{0}{0}{pedregosa_scikitlearn_2011}
\@writefile{toc}{\contentsline {subsection}{\numberline {E.2}Model selection procedures}{22}{subsection.E.2}\protected@file@percent }
\newlabel{apd:experiments:nuisances_hp}{{E.2}{22}{Nuisances estimation}{section*.50}{}}
\@writefile{toc}{\contentsline {paragraph}{Nuisances estimation}{22}{section*.50}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Hyper-parameters grid used for nuisance models\relax }}{22}{table.caption.51}\protected@file@percent }
\newlabel{apd:experiments:nuisances_hp_grid}{{3}{22}{Hyper-parameters grid used for nuisance models\relax }{table.caption.51}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {E.3}Additional Results}{22}{subsection.E.3}\protected@file@percent }
\newlabel{apd:experiments:additional_results}{{E.3}{22}{Additional Results}{subsection.E.3}{}}
\@writefile{toc}{\contentsline {paragraph}{Definition of the Kendall's tau, $\kappa $}{22}{section*.52}\protected@file@percent }
\newlabel{eq:kendall_tau}{{20}{22}{Definition of the Kendall's tau, $\kappa $}{equation.E.20}{}}
\@writefile{toc}{\contentsline {paragraph}{Values of relative $\kappa (\ell ,\tau \mathrm  {{-risk}})$ compared to the mean over all metrics Kendall's as shown in the boxplots of Figure \ref  {fig:relative_kendalls_all_datasets}}{22}{table.caption.54}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Figure \ref  {apd:fig:all_datasets_tau_risk_ranking_agreement} - Results measured in absolute Kendall's}{22}{figure.caption.56}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Figure \ref  {apd:all_datasets_normalized_bias_tau_risk_to_best_method} - Results measured as distance to the oracle tau-risk}{22}{section*.57}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Figure \ref  {apd:fig:procedures_comparison_all_metrics} - Stacked models for the nuisances is more efficient}{22}{section*.59}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Figure \ref  {apd:fig:all_datasets_overlap_effect} Low population overlap hinders model selection for all metrics}{22}{figure.caption.62}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Values of relative $\kappa (\ell ,\tau \mathrm  {{-risk}})$ compared to the mean over all metrics Kendall's as shown in the boxplots of Figure \ref  {fig:relative_kendalls_all_datasets}\relax }}{23}{table.caption.54}\protected@file@percent }
\newlabel{apd:table:relative_kendalls_all_datasets}{{4}{23}{Values of relative $\kappa (\ell ,\tau \mathrm {{-risk}})$ compared to the mean over all metrics Kendall's as shown in the boxplots of Figure \ref {fig:relative_kendalls_all_datasets}\relax }{table.caption.54}{}}
\@writefile{toc}{\contentsline {paragraph}{Figure \ref  {apd:fig:nuisances_comparison} - Stacked models for the nuisances is more efficient}{23}{section*.63}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Figure \ref  {apd:fig:nuisances_comparison_twins} - Flexible models are performant in recovering nuisances even in linear setups}{23}{figure.caption.66}\protected@file@percent }
\newlabel{{apd:results:seed_effect}}{{E.3}{23}{Selecting different seeds and parameters is crucial to draw conclucions}{section*.67}{}}
\@writefile{toc}{\contentsline {paragraph}{Selecting different seeds and parameters is crucial to draw conclucions}{23}{section*.67}\protected@file@percent }
\newlabel{fig:ranking_agreement_w_tau_risk_caussim}{{14a}{24}{\textbf {Caussim}\relax }{figure.caption.56}{}}
\newlabel{sub@fig:ranking_agreement_w_tau_risk_caussim}{{a}{24}{\textbf {Caussim}\relax }{figure.caption.56}{}}
\newlabel{fig:ranking_agreement_tau_risk_acic_2016}{{14b}{24}{\textbf {ACIC 2016}\relax }{figure.caption.56}{}}
\newlabel{sub@fig:ranking_agreement_tau_risk_acic_2016}{{b}{24}{\textbf {ACIC 2016}\relax }{figure.caption.56}{}}
\newlabel{fig:ranking_agreement_w_tau_risk_acic_2018}{{14c}{24}{\textbf {ACIC 2018}\relax }{figure.caption.56}{}}
\newlabel{sub@fig:ranking_agreement_w_tau_risk_acic_2018}{{c}{24}{\textbf {ACIC 2018}\relax }{figure.caption.56}{}}
\newlabel{fig:ranking_agreement_tau_risk_twins}{{14d}{24}{\textbf {TWINS}\relax }{figure.caption.56}{}}
\newlabel{sub@fig:ranking_agreement_tau_risk_twins}{{d}{24}{\textbf {TWINS}\relax }{figure.caption.56}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Agreement with $\tau \text  {-risk}$ ranking of methods function of overlap violation. The lines represent medians, estimated with a lowess. The transparent bands denote the 5\% and 95\% confidence intervals.\relax }}{24}{figure.caption.56}\protected@file@percent }
\newlabel{apd:fig:all_datasets_tau_risk_ranking_agreement}{{14}{24}{Agreement with $\tau \text {-risk}$ ranking of methods function of overlap violation. The lines represent medians, estimated with a lowess. The transparent bands denote the 5\% and 95\% confidence intervals.\relax }{figure.caption.56}{}}
\newlabel{fig:normalized_bias_tau_risk_to_best_method_caussim}{{15a}{25}{\textbf {Caussim}\relax }{figure.caption.58}{}}
\newlabel{sub@fig:normalized_bias_tau_risk_to_best_method_caussim}{{a}{25}{\textbf {Caussim}\relax }{figure.caption.58}{}}
\newlabel{fig:normalized_bias_tau_risk_to_best_method_acic_2016}{{15b}{25}{\textbf {ACIC 2016}\relax }{figure.caption.58}{}}
\newlabel{sub@fig:normalized_bias_tau_risk_to_best_method_acic_2016}{{b}{25}{\textbf {ACIC 2016}\relax }{figure.caption.58}{}}
\newlabel{fig:normalized_bias_tau_risk_to_best_method_acic_2018}{{15c}{25}{\textbf {ACIC 2018}\relax }{figure.caption.58}{}}
\newlabel{sub@fig:normalized_bias_tau_risk_to_best_method_acic_2018}{{c}{25}{\textbf {ACIC 2018}\relax }{figure.caption.58}{}}
\newlabel{fig:normalized_bias_tau_risk_to_best_method_twins}{{15d}{25}{\textbf {TWINS}\relax }{figure.caption.58}{}}
\newlabel{sub@fig:normalized_bias_tau_risk_to_best_method_twins}{{d}{25}{\textbf {TWINS}\relax }{figure.caption.58}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Metric performances by normalized tau-risk distance to the best method selected with $\tau \text  {-risk}$. All nuisances are learned with the same estimator stacking gradient boosting and ridge regression. Doted and plain lines corresponds to 60\% lowess quantile estimates. This choice of quantile allows to see better the oracle metrics lines for which outliers with a value of 0 distord the curves.\relax }}{25}{figure.caption.58}\protected@file@percent }
\newlabel{apd:all_datasets_normalized_bias_tau_risk_to_best_method}{{15}{25}{Metric performances by normalized tau-risk distance to the best method selected with $\tau \text {-risk}$. All nuisances are learned with the same estimator stacking gradient boosting and ridge regression. Doted and plain lines corresponds to 60\% lowess quantile estimates. This choice of quantile allows to see better the oracle metrics lines for which outliers with a value of 0 distord the curves.\relax }{figure.caption.58}{}}
\newlabel{fig:experiments:procedures_comparison:caussim}{{16a}{26}{\textbf {Caussim}\relax }{figure.caption.60}{}}
\newlabel{sub@fig:experiments:procedures_comparison:caussim}{{a}{26}{\textbf {Caussim}\relax }{figure.caption.60}{}}
\newlabel{fig:experiments:procedures_comparison:acic_2016}{{16b}{26}{\textbf {ACIC 2016}\relax }{figure.caption.60}{}}
\newlabel{sub@fig:experiments:procedures_comparison:acic_2016}{{b}{26}{\textbf {ACIC 2016}\relax }{figure.caption.60}{}}
\newlabel{fig:experiments:procedures_comparison:twins}{{16c}{26}{\textbf {Twins}\relax }{figure.caption.60}{}}
\newlabel{sub@fig:experiments:procedures_comparison:twins}{{c}{26}{\textbf {Twins}\relax }{figure.caption.60}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Results are similar between the \leavevmode {\color  {MidnightBlue}Shared nuisances/candidate set} and the \leavevmode {\color  {RedOrange}Separated nuisances set} procedure. The experience has not been run on the full metrics for Caussim due to computation costs.\relax }}{26}{figure.caption.60}\protected@file@percent }
\newlabel{apd:fig:procedures_comparison_all_metrics}{{16}{26}{Results are similar between the \textcolor {MidnightBlue}{Shared nuisances/candidate set} and the \textcolor {RedOrange}{Separated nuisances set} procedure. The experience has not been run on the full metrics for Caussim due to computation costs.\relax }{figure.caption.60}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces \textbf  {Low population overlap hinders causal model selection for all metrics}: Kendall's $\tau $ agreement with $\tau \text  {-risk}$. Strong, medium and Weak overlap correspond to the tertiles of the overlap distribution measured with Normalized Total Varation eq. \ref  {eq:ntv}.\relax }}{27}{figure.caption.62}\protected@file@percent }
\newlabel{apd:fig:all_datasets_overlap_effect}{{17}{27}{\textbf {Low population overlap hinders causal model selection for all metrics}: Kendall's $\tau $ agreement with $\tau \text {-risk}$. Strong, medium and Weak overlap correspond to the tertiles of the overlap distribution measured with Normalized Total Varation eq. \ref {eq:ntv}.\relax }{figure.caption.62}{}}
\newlabel{fig:experiments:nuisance_comparison:twins}{{18a}{28}{\textbf {Twins}\relax }{figure.caption.64}{}}
\newlabel{sub@fig:experiments:nuisance_comparison:twins}{{a}{28}{\textbf {Twins}\relax }{figure.caption.64}{}}
\newlabel{fig:experiments:nuisance_comparison:twins_ds}{{18b}{28}{\textbf {Twins downsampled}\relax }{figure.caption.64}{}}
\newlabel{sub@fig:experiments:nuisance_comparison:twins_ds}{{b}{28}{\textbf {Twins downsampled}\relax }{figure.caption.64}{}}
\newlabel{fig:experiments:nuisance_comparison:caussim}{{18c}{28}{\textbf {Caussim}\relax }{figure.caption.64}{}}
\newlabel{sub@fig:experiments:nuisance_comparison:caussim}{{c}{28}{\textbf {Caussim}\relax }{figure.caption.64}{}}
\newlabel{fig:experiments:nuisance_comparison:acic_2016}{{18d}{28}{\textbf {ACIC 2016}\relax }{figure.caption.64}{}}
\newlabel{sub@fig:experiments:nuisance_comparison:acic_2016}{{d}{28}{\textbf {ACIC 2016}\relax }{figure.caption.64}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Learning the nuisances with \leavevmode {\color  {DarkOrchid}stacked models} (linear and gradient boosting) is important for successful model selection with R-risk. For Twins dataset, there is no improvement for \leavevmode {\color  {DarkOrchid}stacked models} compared to \leavevmode {\color  {ForestGreen}linear models} because of the linearity of the propensity model.\relax }}{28}{figure.caption.64}\protected@file@percent }
\newlabel{apd:fig:nuisances_comparison}{{18}{28}{Learning the nuisances with \textcolor {DarkOrchid}{stacked models} (linear and gradient boosting) is important for successful model selection with R-risk. For Twins dataset, there is no improvement for \textcolor {DarkOrchid}{stacked models} compared to \textcolor {ForestGreen}{linear models} because of the linearity of the propensity model.\relax }{figure.caption.64}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces \textbf  {Flexible models are performant in recovering nuisances in the downsampled Twins dataset.} The propensity score is linear in this setup, making it particularly challenging for flexible models compared to linear methods.\relax }}{28}{figure.caption.66}\protected@file@percent }
\newlabel{apd:fig:nuisances_comparison_twins}{{19}{28}{\textbf {Flexible models are performant in recovering nuisances in the downsampled Twins dataset.} The propensity score is linear in this setup, making it particularly challenging for flexible models compared to linear methods.\relax }{figure.caption.66}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Kendall correlation coefficients for each causal metric. Each (color, shape) pair indicates a different (treatment ratio, seed) of the generation process.\relax }}{29}{figure.caption.68}\protected@file@percent }
\newlabel{apd:results:fig:seed_effect}{{20}{29}{Kendall correlation coefficients for each causal metric. Each (color, shape) pair indicates a different (treatment ratio, seed) of the generation process.\relax }{figure.caption.68}{}}
\abx@aux@cite{0}{nie_quasioracle_2017}
\abx@aux@segm{0}{0}{nie_quasioracle_2017}
\abx@aux@cite{0}{causalevaluations}
\abx@aux@segm{0}{0}{causalevaluations}
\abx@aux@cite{0}{econml}
\abx@aux@segm{0}{0}{econml}
\abx@aux@cite{0}{chernozhukov_double_2018}
\abx@aux@segm{0}{0}{chernozhukov_double_2018}
\abx@aux@cite{0}{chernozhukov_double_2018}
\abx@aux@segm{0}{0}{chernozhukov_double_2018}
\abx@aux@cite{0}{loiseau_external_2022}
\abx@aux@segm{0}{0}{loiseau_external_2022}
\abx@aux@cite{0}{loiseau_external_2022}
\abx@aux@segm{0}{0}{loiseau_external_2022}
\abx@aux@cite{0}{gao_assessment_2021}
\abx@aux@segm{0}{0}{gao_assessment_2021}
\abx@aux@cite{0}{gao_assessment_2021}
\abx@aux@segm{0}{0}{gao_assessment_2021}
\abx@aux@cite{0}{econml}
\abx@aux@segm{0}{0}{econml}
\abx@aux@cite{0}{naimi2021challenges}
\abx@aux@segm{0}{0}{naimi2021challenges}
\abx@aux@cite{0}{naimi2021challenges}
\abx@aux@segm{0}{0}{naimi2021challenges}
\abx@aux@cite{0}{tmle_package_2012}
\abx@aux@segm{0}{0}{tmle_package_2012}
\abx@aux@cite{0}{schuler_comparison_2018}
\abx@aux@segm{0}{0}{schuler_comparison_2018}
\abx@aux@cite{0}{schuler_comparison_2018}
\abx@aux@segm{0}{0}{schuler_comparison_2018}
\@writefile{toc}{\contentsline {section}{\numberline {F}Heterogeneity in practices for data split}{30}{appendix.F}\protected@file@percent }
\newlabel{apd:results:k_fold_choices}{{F}{30}{Heterogeneity in practices for data split}{appendix.F}{}}
\abx@aux@read@bbl@mdfivesum{B1773644B8FC4DFD0CA45AA3345AE245}
\abx@aux@defaultrefcontext{0}{alaa_validating_2019}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{almond_costs_2005}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{altman2009prognosis}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{athey2016recursive}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{athey_generalized_2019}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{austin2017estimating}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{austin_introduction_2011}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{austin_moving_2015}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{econml}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{black1996we}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{blakely2020reflection}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{bouthillier_accounting_2021}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{charlson_new_1987}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{chernozhukov_double_2018}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{colnet2023risk}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{curth_really_2021}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{damour_overlap_2020}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{daniel2018double}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{desai2020comparison}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{dorie_automated_2019}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{dudley2011exploiting}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{fontana2019can}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{gao_assessment_2021}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{gretton2012kernel}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{grose_use_2020}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{tmle_package_2012}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{gutierrez_causal_2016}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{hernan_causal_2020}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{hernan_methods_2021}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{hill_bayesian_2011}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{hoogland2021tutorial}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{horng2017creating}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{howe_splines_2011}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{hurle2013computational}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{imbens_causal_2015}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{ionides_truncated_2008}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{jesson_identifying_2020}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{johansson_generalization_2021}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{kendall_new_1938}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{kennedy2020optimal}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{kunzel_metalearners_2019}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{vanderlaan_unified_2003}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{laan_super_2007}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{laan_targeted_2011}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{lamont2018identification}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{loiseau_external_2022}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{louizos_causal_2017}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{macdorman_infant_1998}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{minderer_revisiting_2021}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{mooney2018bigdata}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{naimi2021challenges}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{naimi2023defining}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{niculescu-mizil_predicting_2005}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{nie_quasioracle_2017}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{niswander_women_1972}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{pedregosa_scikitlearn_2011}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{perez2022beyond}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{perperoglou_review_2019}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{platt_probabilistic_1999}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{poldrack2020establishment}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{powers_methods_2018}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{radley2006off}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{rahimi_random_2008}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{robins_new_1986}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{robins_role_1986}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{robinson_rootnconsistent_1988}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{rolling_model_2014}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{rosenbaum_central_1983}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{rothman2008case}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{rubin_causal_2005}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{saito_counterfactual_2020}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{schulam_reliable_2017}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{schuler_comparison_2018}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{schuler_targeted_2017}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{shalit_estimating_2017}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{causalevaluations}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{shimoni_benchmarking_2018}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{simon2018predicting}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{snowden_implementation_2011}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{sriperumbudur_integral_2009}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{su2018random}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{swaminathan_counterfactual_2015}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{varoquaux2022evaluating}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{wager_estimation_2018}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{wendling_comparing_2018}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{yurkovich2015systematic}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{zadrozny_obtaining_2001}{nyt/global//global/global}
\gdef \@abspage@last{30}
